{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "from pyzotero.zotero import Zotero\n",
    "import os\n",
    "from sqlite3 import connect\n",
    "\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from src.dispatcher import Dispatcher\n",
    "from src.db import ZoteroDatabase\n",
    "from src.scihub import SciHub\n",
    "import src.utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zot = Zotero(os.environ['ZOTERO_USER_ID'], 'user', os.environ['ZOTERO_API_KEY'], preserve_json_order=True)\n",
    "\n",
    "z = ZoteroDatabase(local=True)\n",
    "d = Dispatcher(session=None)\n",
    "\n",
    "items = z.get_items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_abbr(name):\n",
    "    name_lst = name.split()\n",
    "    if sum(c.isalpha() for c in name) > len(name_lst):\n",
    "        return tuple( n[0] + '.'  for n in name_lst )\n",
    "\n",
    "    \n",
    "def fix_name(name_dict, names, safe_mode=True, blacklist_path=None):\n",
    "    \"\"\"\n",
    "    Does the following things in this order:\n",
    "    Adds dots to abbreviated first names.\n",
    "    Tries to complete first names if present in database.\n",
    "    Tries to find additional first names.\n",
    "    Tries to convert full name to first name-last name style.\n",
    "    \n",
    "    Arguments:\n",
    "        name_dict: dict of one creator\n",
    "        names: set of tuples of all names {(firstName, lastName, (first, names, abbreviated))}\n",
    "        safe_mode: bool, skip possibly ambivalent operations\n",
    "        blacklist_path: file path of blacklist json\n",
    "    \n",
    "    Returns:\n",
    "        status: -1: no changes\n",
    "                0: changed\n",
    "                >0: skipped, bitmask\n",
    "        dict of changed name, otherwise None\n",
    "    \"\"\"\n",
    "    status = 0\n",
    "    \n",
    "    if blacklist_path is not None:\n",
    "        with open(blacklist_path, 'r') as f:\n",
    "            blacklist = json.load(f)\n",
    "    \n",
    "        if name_dict in blacklist:\n",
    "            print(\"Skipped: {} blacklisted.\".format(name_dict))\n",
    "            return 1, None\n",
    "    \n",
    "    fnames = name_dict['firstName']\n",
    "    fnames_lst = fnames.split()\n",
    "    lname = name_dict['lastName']\n",
    "    lname_lst = lname.split()\n",
    "    \n",
    "    # convert full names to first name, last name\n",
    "    if len(lname_lst) > 1 and fnames == '':\n",
    "        if safe_mode:\n",
    "            print('Safe Mode: Skipped splitting full name {}'.format(lname))\n",
    "            status += 2\n",
    "        else:\n",
    "            fnames_lst = lname_lst[:-1]\n",
    "            lname = lname_lst[-1]\n",
    "            print('Splitted full name into {} {}'.format(fnames_lst, lname))\n",
    "    \n",
    "    # add dots\n",
    "    names_abbr = tuple( n + '.' if len(n) == 1 else n for n in fnames_lst )\n",
    "    fnames_mod = ' '.join(names_abbr)\n",
    "    \n",
    "    # TODO: find full & additional names simultaneously\n",
    "    full_fnames = list()\n",
    "    add_fnames = list()\n",
    "    for n in names:\n",
    "        if lname == n[1]:\n",
    "            # check for full first names\n",
    "            if names_abbr == n[2]:\n",
    "                full_fnames.append(n[0])\n",
    "            \n",
    "            # check for additional first names\n",
    "            other_fnames = n[0].split()\n",
    "            num_names = len(fnames_lst)\n",
    "            if fnames_lst == other_fnames[:num_names] and num_names < len(other_fnames):\n",
    "                # safe mode: only change if first(!) first name not abbreviated:\n",
    "                if safe_mode:\n",
    "                    if len(other_fnames[0].replace('.', '')) > 1:\n",
    "                        add_fnames.append(n[0])\n",
    "                    else:\n",
    "                        print('Safe Mode: Skipped only abbreviated first name {} {}'.format(n[0], n[1]))\n",
    "                        status += 4\n",
    "                else:\n",
    "                    add_fnames.append(n[0])\n",
    "            \n",
    "    for lst in [add_fnames, full_fnames]:\n",
    "        if len(lst) == 1:\n",
    "            fnames_mod = lst[0]\n",
    "            print('Changed {} into {} {}'.format(fnames, fnames_mod, lname))\n",
    "        elif len(lst) > 1:\n",
    "            print('Skipped: Multiple first names found for {} {}'.format(lst, lname))\n",
    "            status += 8\n",
    "    \n",
    "    name_dict_mod = copy.deepcopy(name_dict)\n",
    "    name_dict_mod['firstName'] = fnames_mod\n",
    "    name_dict_mod['lastName'] = lname\n",
    "    \n",
    "    if status > 0:\n",
    "        return status, None\n",
    "    else:\n",
    "        if name_dict_mod != name_dict:\n",
    "            return status, name_dict_mod\n",
    "        else:\n",
    "            return -1, None\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "names = { ( c.get('firstName', ''), c.get('lastName', ''),\n",
    "            create_abbr(c.get('firstName', '')) ) for i in items for c in i.get('creators', []) }\n",
    "\n",
    "\n",
    "\n",
    "names\n",
    "#fix_name({'firstName': 'Jonathan F', 'lastName': 'Donges'}, names)\n",
    "fix_name({'bla': 1, 'firstName': 'Robert U', 'lastName': 'Ayres'}, names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{'bla': 1, 'firstName': 'Robert U', 'lastName': 'Ayres'} in [{'bla': 1, 'firstName': 'Robert U', 'lastName': 'Ayres'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_name({'firstName': 'R.', 'lastName': 'Ayres'}, {('R. B.', 'Ayres', ('R.', 'B.'))}, safe_mode=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def fix_names(self, keys=[], safe_mode=True, blacklist_path=None):\n",
    "    \"\"\"\n",
    "    Fix names for selected keys\n",
    "    \n",
    "    Arguments\n",
    "        keys: list of keys\n",
    "        safe_mode: if True, skip ambivalent renamings. If blacklist_path not None, create blacklist\n",
    "        blacklist_path: path to blacklist json\n",
    "    \n",
    "    \"\"\"\n",
    "    all_items = self.db.get_items()\n",
    "    names = { ( c.get('firstName', ''), c.get('lastName', ''),\n",
    "            create_abbr(c.get('firstName', '')) ) for i in all_items for c in i.get('creators', []) }\n",
    "    \n",
    "    items = self.db.get_items(keys)\n",
    "\n",
    "    items_mod = list()\n",
    "    skipped = list()\n",
    "    for i in items:\n",
    "        creators_mod = copy.deepcopy(i.get('creators', []))\n",
    "        mod = 0\n",
    "        for n, c in enumerate(i.get('creators', [])):\n",
    "            status, name_mod = fix_name(c, names, safe_mode=safe_mode, blacklist_path=blacklist_path)\n",
    "            if status == 0:\n",
    "                creators_mod[n] = name_mod\n",
    "                mod +=1\n",
    "            elif status > 0:\n",
    "                skipped.append(c)\n",
    "        if mod > 0:\n",
    "            item_mod = {'key': i['key'], 'version': i['version'], 'creators': creators_mod}\n",
    "            items_mod.append(item_mod)\n",
    "    \n",
    "    if blacklist_path is not None:\n",
    "        skipped = [dict(t) for t in {tuple(sorted(d.items())) for d in skipped}]\n",
    "        with open(blacklist_path, 'w') as f:\n",
    "            json.dump(skipped, f, indent=4)\n",
    "            \n",
    "    #self.db.batch_update_items(items_mod)\n",
    "            \n",
    "    return items_mod\n",
    "\n",
    "fix_names(d, blacklist_path='blacklist.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z.get_items(list({'2UYDUXQM': 1}.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from json import JSONDecodeError\n",
    "try:\n",
    "    blacklist = json.loads('')\n",
    "except (FileNotFoundError, json.JSONDecodeError):\n",
    "    blacklist = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item = z.get_items('B9XCY7CH')[0]\n",
    "item = {k: item[k] for k in ['key', 'version', 'creators']}\n",
    "item['creators'] = [{'creatorType': 'author',\n",
    "   'firstName': 'Andreas',\n",
    "   'lastName': 'Chatzidakis'},\n",
    "  {'creatorType': 'author', 'firstName': 'Gretchen', 'lastName': 'Larsen'},\n",
    "  {'creatorType': 'author', 'firstName': 'Simon', 'lastName': 'Bishop'}]\n",
    "\n",
    "z.update_items([item])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z.get_items()\n",
    "z.get_items_creators_local()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = ['XXLF2GYS', 'G3GP7TW8','UYJJPTXG','4SDR5E5R','JTWSQKIS','AG9I49JZ', '7ARSI4KK']\n",
    "item_type = 'note || attachment'\n",
    "\n",
    "# items = z.get_items(keys=keys, use_cache=False)\n",
    "# items = z.get_notes(keys=keys)\n",
    "items = z.get_attachments(keys=keys)\n",
    "items[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_types = ['pdf', 'epub', 'djvu', 'mobi', 'okular'] # alsp PDF!\n",
    "# present_file_type = {a.get('path','').split('.')[-1] for a in attachments}\n",
    "\n",
    "d = Dispatcher(session=None)\n",
    "items = z.get_items(keys=[])\n",
    "\n",
    "\n",
    "def check_filenames(items):\n",
    "    keys = [i['key'] for i in items]\n",
    "    attachments = z.get_attachments(parent_keys=keys)\n",
    "    attachments_dict = {i['key']: [(a['path'], 'attachments:' + d.build_file_name(i)) for a in attachments\n",
    "                                   if a.get('parentItem') == i['key']\n",
    "                                   and 'path' in a \n",
    "                                   and a['path'] != 'attachments:' + d.build_file_name(i)]\n",
    "                        for i in items}\n",
    "    return attachments_dict\n",
    "\n",
    "\n",
    "check_filenames(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_types = ['pdf', 'epub', 'djvu', 'mobi', 'okular'] # also PDF!\n",
    "\n",
    "selected_keys = ['XXLF2GYS', 'G3GP7TW8','UYJJPTXG','4SDR5E5R','JTWSQKIS','AG9I49JZ', '7ARSI4KK']\n",
    "\n",
    "\n",
    "import re\n",
    "\n",
    "def get_doi(item):\n",
    "    \n",
    "    def get_match(s, regex):\n",
    "        r = re.compile(regex, re.IGNORECASE)\n",
    "        match = r.search(s)\n",
    "        if match:\n",
    "            return match.group()\n",
    "        \n",
    "    r = r'10.\\d{4,9}\\/[-._;()/:A-Z0-9]+'\n",
    "    return item.get('DOI') or get_match(item.get('url', ''), r) or get_match(item.get('extra', ''), r)\n",
    "    \n",
    "\n",
    "\n",
    "items = z.get_items(keys=selected_keys)\n",
    "attachments = z.get_attachments(parent_keys=selected_keys)\n",
    "\n",
    "# attachments_dict = {i['key']: [a['path'] for a in attachments\n",
    "#                                if 'path' in a and a.get('parentItem') == i['key']\n",
    "#                                and (a.get('path', '').split('.')[-1]).lower() in file_types] for i in items}\n",
    "# attachments_dict\n",
    "\n",
    "attachment_keys = [a['parentItem'] for a in attachments\n",
    "                   if 'parentItem' in a and (a.get('path', '').split('.')[-1]).lower() in file_types]\n",
    "\n",
    "no_attachments_dict = {i['key']: {'url': i.get('url'), 'DOI': get_doi(i), 'ISBN': i.get('ISBN')} for i in items if i['key'] not in attachment_keys}\n",
    "\n",
    "no_attachments_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z.item_types()\n",
    "z.item_type_fields('note')\n",
    "z.item_attachment_link_modes()\n",
    "# z.item_template('journalArticle')\n",
    "z.item_template('attachment', 'linked_file')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zotero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scihub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'dalsdk-.;asjdn'\n",
    "text = unicodedata.normalize('NFD', text).encode('ascii', 'ignore').decode('utf-8')\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "identifier = '10.1016/j.ssmph.2019.10038'\n",
    "\n",
    "sh = SciHub(use_fallback=False)\n",
    "# sh.available_base_url_list\n",
    "# result = sh.fetch('http://ieeexplore.ieee.org/xpl/login.jsp?tp=&arnumber=1648853')\n",
    "result = sh.download(identifier, path='/home/boris/Downloads/paper.pdf')\n",
    "# sh._get_available_scihub_urls()\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lisc - retrieve DOI relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = Zotero(os.environ['ZOTERO_USER_ID'], 'user', os.environ['ZOTERO_API_KEY'], preserve_json_order=True)\n",
    "item = z.item('2BCDWE4F')['data']\n",
    "# item2 = z.item('7ARSI4KK')\n",
    "item['relations'] = {'dc:relation': ['http://zotero.org/users/5832834/items/TZNEQBL3',\n",
    "                                     'http://zotero.org/users/5832834/items/KQNSY94T',\n",
    "                                     'http://zotero.org/users/5832834/items/PIM5RGMN',\n",
    "                                     'http://zotero.org/users/5832834/items/WDYQMILT']\n",
    "}\n",
    "\n",
    "# items = [{'key': 'AG9I49JZ',\n",
    "#           'note': None,\n",
    "#           'path': None,\n",
    "#           'itemType': 'book',\n",
    "#         'relations': {'dc:relation': ['http://zotero.org/users/5832834/items/7ARSI4KK']}}]\n",
    "items = [item]\n",
    "\n",
    "z.check_items(items)\n",
    "# z.update_items(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lisc.requester import Requester\n",
    "from lisc.urls.open_citations import OpenCitations\n",
    "\n",
    "util = 'references' # citations, references\n",
    "util = 'citations'\n",
    "settings = {'format': 'json'}\n",
    "dois = ['10.1016/S0305-750X(01)00109-7']\n",
    "dois = ['10.1093/oxrep/grx056']\n",
    "\n",
    "urls = OpenCitations()\n",
    "urls.build_url(util=util)\n",
    "\n",
    "url = urls.get_url(util=util, segments=dois, settings=settings)\n",
    "print(url)\n",
    "# urls.authenticate(url)\n",
    "# urls.fill_settings(format='json')\n",
    "# urls.check_url(util)\n",
    "\n",
    "req = Requester(wait_time=0.1, logging=None)\n",
    "# req.check()\n",
    "r = req.request_url(url)\n",
    "req.close()\n",
    "r.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Toolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prompt_toolkit.completion import NestedCompleter, WordCompleter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp = {'do': {'this': None,\n",
    "               WordCompleter(['that']): WordCompleter(['thing'])\n",
    "              } \n",
    "       }\n",
    "NestedCompleter.from_nested_dict(comp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
